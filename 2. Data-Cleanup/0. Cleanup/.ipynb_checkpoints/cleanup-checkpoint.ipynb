{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Steps\n",
    "\n",
    "1. Understand the data structure: Look through the database, understand the main structure, i.e., what each row represents, and what columns and types of information are available\n",
    "2. Merge game file to add in week identifier to the new dataset (games.csv is in '1. Additional Data File')\n",
    "3. Create column categorizations to filter dataset for relevant purposes\n",
    "4. Break down receiver into its individual row\n",
    "5. Create playmaker column, and check id uniqueness - check that one ID corresponds to one name\n",
    "6. Flag non-relevant plays - add a binary column that flags 1 for run, pass, reception, FG/XP, 0 for all others\n",
    "7. Add any additional stat needed - reception (for plays that fall under 'reception'), target ('reception', 'pass')\n",
    "8. Add position based off of the highest stat of a player. Position will be refined later with web scraping\n",
    "9. Ensure that stat are correctly represented for a given position\n",
    "10. Verify top 50 stats against the reported ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import ExcelWriter\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Not sure why your folder names were changes. The working directory of this file is where its source code is located\n",
    "so you can specify directories relatively\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store your files in the same folder as the source code, so you don't have to specify the directory\n",
    "df_file_2019 = \"../../1. Raw-Data/data2019.csv\"\n",
    "df_file_game = \"../1. Additional-Data/games.csv\"\n",
    "\n",
    "# Use the convention df for dataframes\n",
    "df = pd.read_csv(df_file_2019)\n",
    "df_games = pd.read_csv(df_file_game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add in Weekly Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Headings need to be more descriptive and properly formatted\n",
    "Removed unused or unecessary code\n",
    "No need to create new dataframes, just replace the old one\n",
    "All set up commans to be placed in the setup section\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_games[[\"game_id\", \"week\"]], on = 'game_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Categorization Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Automated creation of most of these\n",
    "A lot of elements need to be re categorized\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Main Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"key\" list that contains elements that will always be needed - game id, week, play type\n",
    "key = []\n",
    "\n",
    "# There are so many elements here that are missing here\n",
    "# touchdown, passing toucdown, rushing touchdown, pass attemps, rush attempts, interceptions, fumble lost, 2 point attempts and conversions and so on\n",
    "# all elements that contribute to points in fantasy should be in the main lists\n",
    "\n",
    "pass_play = ['pass_length','pass_location','air_yards']\n",
    "run_play = ['run_location', 'run_gap']\n",
    "yard_info = ['yrdln','ydstogo','ydsnet','yards_gained', \"fumble_recovery_1_yards\", \"fumble_recovery_2_yards\", \"return_yards\", \"\"]\n",
    "receiver_stats = [\"receiver_player_id\", \"receiver_player_name\", \"lateral_receiver_player_name\", \"lateral_receiver_player_name\", \"yards_after_catch\"]\n",
    "# Two point conv should not be in xp\n",
    "# xp + fg\n",
    "xp = ['field_goal_result', 'kick_distance', 'extra_point_result', 'two_point_conv_result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Other Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_info = ['play_id','game_id','home_team','away_team','posteam','posteam_type', 'defteam', 'side_of_field', 'yardline_100','game_date', \"year\"]\n",
    "game_time_info = ['quarter_seconds_remaining', 'half_seconds_remaining', 'game_seconds_remaining', 'game_half', 'quarter_end', 'time']\n",
    "\n",
    "# Keep play type in the main lists\n",
    "gen_play_info = ['drive', 'sp', 'down', 'goal_to_go','desc','play_type','shotgun','no_huddle','qb_dropback','qb_kneel','qb_spike','qb_scramble',]\n",
    "\n",
    "# automate - see below for best example\n",
    "timeout_info = ['home_timmouts_remaining','away_timeouts_remaining','timeout','timeout_team']\n",
    "\n",
    "team_info = [\"return_team\", 'td_team', 'posteam_time', 'defteam_time', 'total_home_score','total_away_score', 'posteam_score_post','defteam_score_post', 'score_differential', \"forced_fumble_player_1_team\", \"forced_fumble_player_2_team\", \"solo_tackle_1_team\", \"solo_tackle_2_team\", \"assist_tackle_1_team\", \"assist_tackle_2_team\", \"assist_tackle_3_team\", \"assist_tackle_4_team\", \"fumbled_1_team\", \"fumbled_2_team\", \"fumble_recovery_1_team\", \"fumble_recovery_2_team\"]\n",
    "\n",
    "# automate\n",
    "probability_info = ['no_score_prob','opp_fg_prob', 'opp_safety_prob', 'opp_td_prob', 'fg_prob', 'safety_prob', 'td_prob', 'extra_point_prob', 'two_point_conversion_prob', 'ep', 'epa', 'total_home_epa','total_away_epa', 'total_home_rush_epa','total_away_rush_epa', 'total_home_pass_epa', 'total_away_pass_epa', 'air_epa', 'yac_epa', 'comp_air_epa', 'total_home_comp_air_epa', 'total_away_comp_air_epa', 'total_home_comp_yac_epa', 'total_away_comp_yac_epa', 'total_home_raw_air_epa', 'total_away_raw_air_epa', 'total_home_raw_yac_epa', 'total_away_raw_yac_epa', 'wp', 'def_wp', 'home_wp', 'away_wp', 'wpa', 'home_wp_post', 'away_wp_post', 'total_home_rush_wpa', 'total_away_rush_wpa', 'total_home_pass_wpa', 'total_away_pass_wpa', 'air_wpa', 'yac_wpa', 'comp_air_wpa', 'comp_yac_wpa', 'total_home_comp_air_wpa', 'total_away_comp_air_wpa', 'total_home_comp_yac_wpa', 'total_away_comp_yac_wpa', 'total_home_raw_air_wpa', 'total_away_raw_air_wpa', 'total_home_raw_yac_wpa', 'total_away_raw_yac_wpa']\n",
    "\n",
    "# a lot of these need to be re categorized\n",
    "# you can easily create a \"down\" list\n",
    "# there's a bunch of defensive stats in there that you can add to the defensive column, samewith punts, safety and what not\n",
    "miscellaneous_plays = ['punt_blocked', 'first_down_rush', 'first_down_pass', 'first_down_penalty', 'third_down_converted', 'third_down_failed', 'fourth_down_converted', 'fourth_down_failed', 'incomplete_pass', 'touchback', 'interception', 'fumble_forced', 'fumble_not_forced', 'fumble_out_of_bounds', 'solo_tackle', 'safety', 'penalty', 'tackled_for_loss', 'fumble_lost', 'qb_hit', 'rush_attempt', 'pass_attempt', 'sack', 'touchdown', 'pass_touchdown', 'rush_touchdown', 'return_touchdown', 'two_point_attempt', 'field_goal_attempt', 'kickoff_attempt', 'punt_attempt', 'fumble', \"complete_pass\", \"assisted_tackle\", \"lateral_reception\", \"lateral_rush\", \"lateral_return\", \"lateral_recovery\"]\n",
    "\n",
    "# automate\n",
    "kickoff_punt_info = ['punt_inside_twenty', 'punt_in_endzone', 'punt_out_of_bounds', 'punt_downed', 'punt_fair_catch', 'kickoff_inside_twenty', 'kickoff_in_endzone', 'kickoff_out_of_bounds', 'kickoff_downed', 'kickoff_fair_catch', 'own_kickoff_recovery', 'own_kickoff_recovery_td']\n",
    "\n",
    "# Add to passer/rusher/reception/kicker and so on columns\n",
    "player_info = [\"passer_player_id\", \"passer_player_name\", \"receiver_player_id\", \"receiver_player_name\", \"rusher_player_id\", \"rusher_player_name\", \"lateral_receiver_player_id\", \"lateral_receiver_player_name\", \"lateral_rusher_player_id\", \"lateral_rusher_player_name\", \"lateral_sack_player_id\", \"lateral_sack_player_name\", \"lateral_sack_player_name\", \"interception_player_id\", \"interception_player_name\", \"lateral_interception_player_id\", \"lateral_interception_player_name\", \"punt_returner_player_id\", \"punt_returner_player_name\", \"lateral_punt_returner_player_id\", \"lateral_punt_returner_player_name\", \"kickoff_returner_player_name\", \"kickoff_returner_player_id\", \"lateral_kickoff_returner_player_id\", \"lateral_kickoff_returner_player_name\", \"punter_player_id\", \"punter_player_name\", \"kicker_player_name\", \"kicker_player_id\", \"own_kickoff_recovery_player_id\", \"own_kickoff_recovery_player_name\", \"blocked_player_id\", \"tackle_for_loss_1_player_id\", \"tackle_for_loss_1_player_name\", \"tackle_for_loss_2_player_id\", \"tackle_for_loss_2_player_name\", \"qb_hit_1_player_id\", \"qb_hit_1_player_name\", \"qb_hit_2_player_id\", \"qb_hit_2_player_name\", \"forced_fumble_player_1_player_id\", \"forced_fumble_player_1_player_name\", \"forced_fumble_player_2_player_id\", \"forced_fumble_player_2_player_name\", \"solo_tackle_1_player_id\", \"solo_tackle_2_player_id\", \"solo_tackle_1_player_name\", \"solo_tackle_2_player_name\", \"assist_tackle_1_player_id\", \"assist_tackle_1_player_name\", \"assist_tackle_2_player_id\", \"assist_tackle_2_player_name\", \"assist_tackle_3_player_id\", \"assist_tackle_3_player_name\",  \"assist_tackle_4_player_id\", \"assist_tackle_4_player_name\",  \"pass_defense_1_player_id\", \"pass_defense_1_player_name\", \"pass_defense_2_player_id\", \"pass_defense_2_player_name\", \"fumbled_1_player_id\", \"fumbled_1_player_name\", \"fumbled_2_player_id\", \"fumbled_2_player_name\", \"fumble_recovery_1_player_id\", \"fumble_recovery_1_player_name\",  \"fumble_recovery_2_player_id\", \"fumble_recovery_2_player_name\"]\n",
    "\n",
    "# automate, why is there an empty column\n",
    "penalty_info = [\"penalty_team\", \"penalty_player_id\", \"penalty_player_name\", \"penalty_yards\", \"replay_or_challenge\", \"replay_or_challenge_result\", \"penalty_type\", \"\"]\n",
    "\n",
    "# automate\n",
    "defensive_points = [\"defensive_two_point_attempt\", \"defensive_extra_point_attempt\", \"defensive_extra_point_conv\"]\n",
    "\n",
    "# Create a final list which includes all elements not currently grouped. Then examine the list and see if you\n",
    "# can recategorize some elements\n",
    "\n",
    "# giant list = sum of all list\n",
    "# df.columns\n",
    "# remaining = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We often use list comprehensions when building out list out of conditions\n",
    "# They have a better performance that for loops, and provide for neater code\n",
    "\n",
    "prob_cols = [col for col in df.columns if 'prob' in col]\n",
    "\n",
    "# The above line does the same thing as the code blow below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete\n",
    "probability_info2 = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if 'prob' in col:\n",
    "        probability_info2.append(col)\n",
    "\n",
    "# do the same for other catagories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change Header\n",
    "Remove redundant code\n",
    "use the new filtering method to create the duplicate df and re add it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete\n",
    "# finds the row index where each pass play is located\n",
    "\n",
    "pass_ls = []\n",
    "pass_row_num = 0\n",
    "for i in data[\"play_type\"]:\n",
    "    if i == \"pass\":\n",
    "        pass_ls.append(pass_row_num)\n",
    "    pass_row_num += 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete\n",
    "\n",
    "\n",
    "# uses the row indecies to add the pass plays to a new dataframe\n",
    "\n",
    "pass_rows = pd.DataFrame()\n",
    "\n",
    "for i in pass_ls:\n",
    "    new_row = data.iloc[i]  \n",
    "    pass_rows = pass_rows.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify\n",
    "data[(data['play_type']==\"pass\")].head()\n",
    "new_df['play_type'] = 'reception'\n",
    "df  = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change Header\n",
    "Remove redundant code\n",
    "The idea here is good but there's way too much code\n",
    "I written a code that perform step 5 in a different way. Feel free to use it, or use its structure to recreate your code\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roy's Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[\"Playmaker_id\"] = \"\"\n",
    "\n",
    "play_ls = []\n",
    "id_dict = {}\n",
    "row_num = 0\n",
    "\n",
    "for i in data[\"play_type\"]:\n",
    "    \n",
    "    if i == \"pass\":\n",
    "        curr_id = data[\"passer_player_id\"][row_num]\n",
    "        if (data[\"passer_player_id\"][row_num] not in play_ls):\n",
    "            id_dict[curr_id] = data[\"passer_player_name\"][row_num]\n",
    "        play_ls.append(data[\"passer_player_id\"][row_num])\n",
    "        \n",
    "        \n",
    "    elif i == \"kickoff\":\n",
    "        curr_id = data[\"kicker_player_id\"][row_num]\n",
    "        if (data[\"kicker_player_id\"][row_num] not in play_ls):\n",
    "            id_dict[curr_id] = data[\"kicker_player_name\"][row_num]\n",
    "        play_ls.append(data[\"kicker_player_id\"][row_num])\n",
    "        \n",
    "        \n",
    "    elif i == \"run\" or i == \"qb_kneel\":\n",
    "        curr_id = data[\"rusher_player_id\"][row_num]\n",
    "        if (data[\"rusher_player_id\"][row_num] not in play_ls):\n",
    "            id_dict[curr_id] = data[\"rusher_player_name\"][row_num]\n",
    "        play_ls.append(data[\"rusher_player_id\"][row_num])\n",
    "        \n",
    "        \n",
    "    elif i == \"punt\":\n",
    "        curr_id = data[\"punter_player_id\"][row_num]\n",
    "        if (data[\"punter_player_id\"][row_num] not in play_ls):\n",
    "            id_dict[curr_id] = data[\"punter_player_name\"][row_num]\n",
    "        play_ls.append(data[\"punter_player_id\"][row_num])\n",
    "        \n",
    "        \n",
    "    elif i == \"field_goal\":\n",
    "        curr_id = data[\"kicker_player_id\"][row_num]\n",
    "        if (data[\"kicker_player_id\"][row_num] not in play_ls):\n",
    "            id_dict[curr_id] = data[\"kicker_player_name\"][row_num]\n",
    "        play_ls.append(data[\"kicker_player_id\"][row_num])\n",
    "        \n",
    "        \n",
    "    elif i == \"extra_point\":\n",
    "        curr_id = data[\"kicker_player_id\"][row_num]\n",
    "        if (data[\"kicker_player_id\"][row_num] not in play_ls):\n",
    "            id_dict[curr_id] = data[\"kicker_player_name\"][row_num]\n",
    "        play_ls.append(data[\"kicker_player_id\"][row_num])\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        play_ls.append(\"N/A\")\n",
    "    \n",
    "           \n",
    "    row_num += 1\n",
    "\n",
    "\n",
    "data[\"Playmaker_id\"] = play_ls\n",
    "\n",
    "data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the player ids in specified columns\n",
    "passer_ls = []\n",
    "kickers_ls = []\n",
    "rusher_ls = []\n",
    "punter_ls = []\n",
    "\n",
    "# appends all the player id in the column to corresponding list\n",
    "for passers in data[\"passer_player_id\"]:\n",
    "    passer_ls.append(passers)\n",
    "    \n",
    "for kickers in data[\"kicker_player_id\"]:\n",
    "    kickers_ls.append(kickers)\n",
    "    \n",
    "for rusher in data[\"rusher_player_id\"]:\n",
    "    rusher_ls.append(rusher)\n",
    "    \n",
    "for punter in data[\"punter_player_id\"]:\n",
    "    punter_ls.append(punter)\n",
    "\n",
    "# these lists will contain the names of the players in the order they appear in the dataframe\n",
    "passer_names = []\n",
    "kickers_names = []\n",
    "rusher_names = []\n",
    "punter_names = []\n",
    "\n",
    "# the player IDs are used to retrieve the corresponding name from the dictionary\n",
    "# in the dictionary one name corresponds to one ID which ensures uniqueness\n",
    "\n",
    "for i in passer_ls:\n",
    "    passer_names.append(id_dict[i])\n",
    "\n",
    "for i in kickers_ls:\n",
    "    kickers_names.append(id_dict[i])\n",
    "\n",
    "for i in rusher_ls:\n",
    "    rusher_names.append(id_dict[i])\n",
    "\n",
    "for i in punter_ls:\n",
    "    punter_names.append(id_dict[i])\n",
    "\n",
    "# the list of names formed above are used unique as only one name is assigned per player, and the list is assigned to each column\n",
    "data[\"passer_player_name\"] = passer_names\n",
    "data[\"kicker_player_name\"] = kickers_names\n",
    "data[\"rusher_player_name\"] = rusher_names\n",
    "data[\"punter_player_name\"] = punter_names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = []\n",
    "player_count = 0\n",
    "ID_count = 0\n",
    "for i in data[\"passer_player_name\"].unique():\n",
    "    player_count += 1\n",
    "    check_list.append(i)\n",
    "for i in data[\"kicker_player_name\"].unique():\n",
    "#     print(i)\n",
    "    player_count += 1\n",
    "    check_list.append(i)\n",
    "for i in data[\"rusher_player_name\"].unique():\n",
    "    player_count += 1\n",
    "    check_list.append(i)\n",
    "for i in data[\"punter_player_name\"].unique():\n",
    "    player_count += 1\n",
    "    check_list.append(i)\n",
    "\n",
    "# print(player_count)\n",
    "print(len(id_dict))\n",
    "# print(len(check_list))\n",
    "new_frame = pd.DataFrame()\n",
    "new_frame['name'] = check_list\n",
    "\n",
    "for i in new_frame['name'].unique():\n",
    "#     print(i)\n",
    "    ID_count += 1\n",
    "\n",
    "print(ID_count)\n",
    "\n",
    "\n",
    "# print(check_list)\n",
    "\n",
    "\n",
    "\n",
    "# for i in new_frame['ID'].unique():\n",
    "#     ID_count += 1\n",
    "\n",
    "# print(ID_count)\n",
    "\n",
    "new_frame\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steven's Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S5.1 Define Play Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create play maker column\n",
    "# you will need to add a receiver segments as well\n",
    "df['play_maker'] = np.where(df['play_type']=='rush',df['rusher'],np.NaN)\n",
    "df['play_maker'] = np.where(df['play_type']=='pass',df['passer'],df['play_maker'])\n",
    "df['play_maker'] = np.where((df['play_type']=='extra_point')|(df['play_type']=='field_goal'),df['kicker'],df['play_maker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in corresponding play maker ID\n",
    "df['play_maker_id'] = np.where(df['play_type']=='rush',df['rusher_player_id'],np.NaN)\n",
    "df['play_maker_id'] = np.where(df['play_type']=='pass',df['passer_player_id'],df['play_maker_id'])\n",
    "df['play_maker_id'] = np.where((df['play_type']=='extra_point')|(df['play_type']=='field_goal'),df['kicker_player_id'],df['play_maker_id'])\n",
    "\n",
    "# Now that we have a single column to identify play makers, it is a lot easier to check for ID uniqueness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S5.2 Identify Non Unique Player Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame that contains the unique count of each player name under a given ID\n",
    "# Filter on the IDs that correspond to more than one name\n",
    "\n",
    "nunique_id = df[df.groupby(['play_maker_id'])['play_maker'].transform('nunique') > 1]['play_maker_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all the duplicate names\n",
    "\n",
    "df[df['play_maker_id'].isin(nunique_id)]['play_maker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of what the corrected names should be\n",
    "\n",
    "name_corrections = {'D.Chark Jr.': 'D.Chark',\n",
    "'Jos.Allen':'J.Allen',\n",
    "'M.Ingram II': 'M.Ingram',\n",
    "'A.Levine Sr.': 'A.Levine',\n",
    "'R.Griffin III': 'R.Griffin',\n",
    "'G.Minshew II':'G.Minshew',\n",
    "'B.Snell Jr.':'B.Snell', \n",
    "'Tr.Edmunds':'T.Edmunds',\n",
    "'R.James Jr.': 'R.James',\n",
    "'J.Ross III':'J.Ross',\n",
    "'W.Snead IV':'W.Snead', \n",
    "'M.Jones Jr.': 'M.Jones', \n",
    "'M.Sanu Sr.':'M.Sanu', \n",
    "'O.Beckham Jr.':'O.Beckham', \n",
    "'P.Dorsett II':'P.Dorsett'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S5.3 Correct Name Uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to correct the typos\n",
    "\n",
    "def typo_correction(name):\n",
    "    if name in name_corrections.keys():\n",
    "        return name_corrections[name]\n",
    "    else:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the dataframe\n",
    "\n",
    "df['play_maker'] = df['play_maker'].apply(typo_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S5.4 New Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['passer_player_id'].isin(nunique_id)].groupby(['passer_player_id','passer_player_name']).size().reset_index()\n",
    "test.set_index('passer_player_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {player_id:(test.loc[player_id,'passer_player_name'][0],test.loc[player_id,'passer_player_name'][1]) for player_id in nunique_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.set_index('passer_player_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dup in d.keys():\n",
    "    test2.loc[dup,'passer_player_name'] = d[dup][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add more descriptive titles\n",
    "Re create this step using the where statements that i've used in the previous code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # step 6:\n",
    "relevance_ls = []\n",
    "data[\"Flag\"] = \"\"\n",
    "# row_num = 1\n",
    "for i in data[\"play_type\"]:\n",
    "    if i == \"run\" or i == \"pass\":\n",
    "        relevance_ls.append(1)\n",
    "#         data[\"Play_relevance\"] = 1\n",
    "    else:\n",
    "        relevance_ls.append(0)\n",
    "#         data[\"Play_relevance\"] = 0\n",
    "\n",
    "# Add field goal, extra points, qb_kneels and reception when done with step 4\n",
    "data[\"Flag\"] = relevance_ls\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
